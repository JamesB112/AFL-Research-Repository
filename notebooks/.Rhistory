dpi = 300,
limitsize = TRUE,
bg = NULL,
)
ggplot(datas, aes(fill=Type, y=Rideshare_Demand, x=Hour)) +
geom_bar(width = 0.8, position="dodge", stat="identity") + ggtitle("Comparison of Estimated Rideservice Demand for Brooklyn 1st March 2022") +
xlab("Hour") + ylab("Number of Trips in Brooklyn") + labs(fill = "Estimate Type")
ggsave(
'March 1st 2022 Brooklyn Prediction',
plot = last_plot(),
path = '../Plots',
scale = 1,
width = NA,
height = NA,
dpi = 300,
limitsize = TRUE,
bg = NULL,
)
ggplot(datas, aes(fill=Type, y=Rideshare_Demand, x=Hour)) +
geom_bar(width = 0.8, position="dodge", stat="identity") + ggtitle("Comparison of Estimated Rideservice Demand for Brooklyn 1st March 2022") +
xlab("Hour") + ylab("Number of Trips in Brooklyn") + labs(fill = "Estimate Type")
ggsave(
'March 1st 2022 Brooklyn Prediction',
plot = last_plot(),
device = 'png',
path = '../Plots',
scale = 1,
width = NA,
height = NA,
dpi = 300,
limitsize = TRUE,
bg = NULL,
)
ggplot(datas, aes(fill=Type, y=Rideshare_Demand, x=Hour)) +
geom_bar(width = 0.8, position="dodge", stat="identity") + ggtitle("Comparison of Estimated Rideservice Demand for Brooklyn 1st March 2022") +
xlab("Hour") + ylab("Number of Trips in Brooklyn") + labs(fill = "Estimate Type")
ggsave(
'March 1st 2022 Brooklyn Prediction',
plot = last_plot(),
device = 'png',
path = '../Plots',
scale = 1,
width = NA,
height = NA,
dpi = 300,
)
ggplot(datas, aes(fill=Type, y=Rideshare_Demand, x=Hour)) +
geom_bar(width = 0.8, position="dodge", stat="identity") + ggtitle("Comparison of Estimated Rideservice Demand for Brooklyn 1st March 2022") +
xlab("Hour") + ylab("Number of Trips in Brooklyn") + labs(fill = "Estimate Type")
ggsave(
'March_1st_2022_Brooklyn_Prediction',
plot = last_plot(),
device = 'png',
path = '../Plots',
scale = 1,
width = NA,
height = NA,
dpi = 300,
)
ggplot(datas, aes(fill=Type, y=Rideshare_Demand, x=Hour)) +
geom_bar(width = 0.8, position="dodge", stat="identity") + ggtitle("Comparison of Estimated Rideservice Demand for Brooklyn 1st March 2022") +
xlab("Hour") + ylab("Number of Trips in Brooklyn") + labs(fill = "Estimate Type")
ggsave(
'March_1st_2022_Brooklyn_Prediction',
plot = last_plot(),
device = 'png',
path = '../Plots',
scale = 1,
dpi = 300,
)
ggplot(datas, aes(fill=Type, y=Rideshare_Demand, x=Hour)) +
geom_bar(width = 0.8, position="dodge", stat="identity") + ggtitle("Comparison of Estimated Rideservice Demand for Brooklyn 1st March 2022") +
xlab("Hour") + ylab("Number of Trips in Brooklyn") + labs(fill = "Estimate Type")
ggsave(
'March_1st_2022_Brooklyn_Prediction.png',
plot = last_plot(),
device = 'png',
path = '../Plots',
scale = 1,
dpi = 300,
)
plot(model_NB_I)
plot(model_P_Final)
# lets take the 1st of march for Brooklyn, the most variate
test_case <- test_data[test_data$Borough_Zone == 'Manhattan_Boro Zone' & test_data$Date == '2022-03-01',]
test_case <- subset(test_case, select = -c(Date))
rownames(test_case) <- test_case$Hour
Pois_predict <- predict(model_P_Final,newdata = test_case, type = 'response')
NegBin_predict <- predict(model_NB_I,newdata = test_case, type = 'response')
# create a dataset
Type <- c(rep("Poisson Estimate" , 24) , rep("Neg.Bin. Estimate" , 24) , rep("Ground Truth" , 24))
Hour <- rep(test_case$Hour , 3)
Rideshare_Demand <- c(Pois_predict, NegBin_predict, test_case$Count)
datas <- data.frame(Model,Hour,val)
ggplot(datas, aes(fill=Type, y=Rideshare_Demand, x=Hour)) +
geom_bar(width = 0.8, position="dodge", stat="identity") + ggtitle("Comparison of Estimated Rideservice Demand for Brooklyn 1st March 2022") +
xlab("Hour") + ylab("Number of Trips in Brooklyn") + labs(fill = "Estimate Type")
ggsave(
'March_1st_2022_Brooklyn_Prediction.png',
plot = last_plot(),
device = 'png',
path = '../Plots',
scale = 1,
dpi = 300,
)
# lets take the 1st of march for Brooklyn, the most variate
test_case <- test_data[test_data$Borough_Zone == 'Brooklyn' & test_data$Date == '2022-03-01',]
test_case <- subset(test_case, select = -c(Date))
rownames(test_case) <- test_case$Hour
Pois_predict <- predict(model_P_Final,newdata = test_case, type = 'response')
NegBin_predict <- predict(model_NB_I,newdata = test_case, type = 'response')
# create a dataset
Type <- c(rep("Poisson Estimate" , 24) , rep("Neg.Bin. Estimate" , 24) , rep("Ground Truth" , 24))
Hour <- rep(test_case$Hour , 3)
Rideshare_Demand <- c(Pois_predict, NegBin_predict, test_case$Count)
datas <- data.frame(Model,Hour,val)
ggplot(datas, aes(fill=Type, y=Rideshare_Demand, x=Hour)) +
geom_bar(width = 0.8, position="dodge", stat="identity") + ggtitle("Comparison of Estimated Rideservice Demand for Brooklyn 1st March 2022") +
xlab("Hour") + ylab("Number of Trips in Brooklyn") + labs(fill = "Estimate Type")
ggsave(
'March_1st_2022_Brooklyn_Prediction.png',
plot = last_plot(),
device = 'png',
path = '../Plots',
scale = 1,
dpi = 300,
)
plot(model_NB_I, caption = 'ff)
plot(model_NB_I, caption = 'ff')
plot(model_NB_I, which = c(1,2,3), sub.caption = FALSE)
plot(model_NB_I, which = c(1,2,3), sub.caption = '')
plot(model_P_Final, which = c(1,2,3), sub.caption = '')
summary(model_NB_I)
bb <- summary(model_NB_I)
bb
bb <- summary(model_NB_I)
plot(model_NB_I, sub.caption = '')
plot(model_P_Final, sub.caption = '')
model_P_Final$residuals
avg(model_P_Final$residuals)
sum(model_P_Final$residuals) / length(model_P_Final$residuals)
ggploy
ggplo
ggplot
library(ggplot2)
ggplot
# Compute a correlation matrix
corr <- round(cor(taxi_data), 1)
taxi_data = read.csv('../data/curated/model_data.csv')
taxi_data <- taxi_data[order(taxi_data$Date, taxi_data$Hour),]
taxi_data$Hour <- as.factor(taxi_data$Hour)
# Compute a correlation matrix
corr <- round(cor(taxi_data), 1)
taxi_data
taxi_data$Date_seq <-  as.Date(taxi_data$Date)
taxi_data$Date_seq <- as.integer(taxi_data$Date_seq - taxi_data$Date_seq[1])
# Compute a correlation matrix
corr <- round(cor(taxi_data), 1)
# Compute a correlation matrix
corr <- round(cor(taxi_data), 1)
# Compute a correlation matrix
corr <- round(cor(taxi_data[, c(4,5,6,7,9,10)]), 1)
taxi_data[, c(4,5,6,7,9,10)]
# Compute a correlation matrix
corr <- cor(taxi_data[, c(4,5,6,7,9,10)])
# Compute a correlation matrix
corr <- cor(taxi_data[, c(4,5,6,7,9)])
head(corr)
taxi_data$Date_seq
type(taxi_data$Date_seq)
class(taxi_data$Date_seq)
taxi_data$Date_seq <-  as.Date(taxi_data$Date)
taxi_data$Date_seq <- integer(taxi_data$Date_seq - taxi_data$Date_seq[1])
integer(taxi_data$Date_seq)
integer('d')
integer('1')
integer('2')
# Compute a correlation matrix
corr <- cor(taxi_data[, c(4,10)])
taxi_data$Date_seq <-  as.Date(taxi_data$Date)
taxi_data$Date_seq <- as.numeric(taxi_data$Date_seq - taxi_data$Date_seq[1])
taxi_data$Date_seq <-  as.Date(taxi_data$Date)
taxi_data$Date_seq <- as.numeric(taxi_data$Date_seq - taxi_data$Date_seq[1])
# Compute a correlation matrix
corr <- cor(taxi_data[, c(4,5,6,7,9,10)])
taxi_data
taxi_data$Date_seq
# Compute a correlation matrix
corr <- cor(taxi_data[, c(4,5,6,7,9)])
head(corr)
taxi_data$Date_seq <-  as.Date(taxi_data$Date)
taxi_data$Date_seq <- as.numeric(taxi_data$Date_seq - taxi_data$Date_seq[1])
# Compute a correlation matrix
corr <- cor(taxi_data[, c(4,5,6,7,9, 10)])
class(taxi_data$Date_seq)
taxi_data
taxi_data[, c(4, 5, 6, 7, 9, 10)]
class(taxi_data$Covid_7AVG)
# Compute a correlation matrix
corr <- cor(taxi_data[, c(4,5,6,7,9)])
head(corr)
# Compute a correlation matrix
corr <- cor(taxi_data[, c(4,5,6,7,9)])
head(corr)
taxi_data$Date_seq <-  as.Date(taxi_data$Date)
taxi_data$Date_seq <- as.integer(taxi_data$Date_seq - taxi_data$Date_seq[1])
# Compute a correlation matrix
corr <- cor(taxi_data[, c(4,5,6,7,9)])
head(corr)
# Compute a correlation matrix
corr <- cor(taxi_data[, c(4,5,6,7,9)])
ggcorrplot(corr)
library(ggplot2)
# Compute a correlation matrix
corr <- cor(taxi_data[, c(4,5,6,7,9)])
ggcorrplot(corr)
taxi_data = read.csv('../data/curated/model_data.csv')
taxi_data <- taxi_data[order(taxi_data$Date, taxi_data$Hour),]
taxi_data$Hour <- as.factor(taxi_data$Hour)
taxi_data$Date_seq <-  as.Date(taxi_data$Date)
taxi_data$Date_seq <- as.integer(taxi_data$Date_seq - taxi_data$Date_seq[1])
training_data <- taxi_data[which(taxi_data$Date < "2022-03-01"),]
test_data <- taxi_data[which(taxi_data$Date >= "2022-03-01"),]
dim(taxi_data)
taxi_data
#Mean
sum(training_data$Count) / length(training_data$Count)
# Variance
var(training_data$Count)
summary(model_P_Final)
anova(model_P_Final)
summary(model_P)
tt <- summary(model_P_Final)
tt$terms
tt$aliased
tt$terms
tt$coefficients
taxi_data = read.csv('../data/curated/model_data.csv')
taxi_data <- taxi_data[order(taxi_data$Date, taxi_data$Hour),]
taxi_data$Hour <- as.factor(taxi_data$Hour)
taxi_data$Date_seq <-  as.Date(taxi_data$Date)
taxi_data$Date_seq <- as.integer(taxi_data$Date_seq - taxi_data$Date_seq[1])
training_data <- taxi_data[which(taxi_data$Date < "2022-03-01"),]
test_data <- taxi_data[which(taxi_data$Date >= "2022-03-01"),]
training_data = subset(training_data, select = -c(Date))
# Normal
model_P <- glm(Count ~ Date_seq + Day + Borough_Zone + DEW + TMP + WND + holiday + Covid_7AVG + Hour,data = training_data, family = poisson())
# This is for interaction
model_P_I <- glm(Count ~ Date_seq + DEW + TMP + WND + holiday + Covid_7AVG + Hour + Day + Borough_Zone + Day*Borough_Zone + holiday*Borough_Zone + Hour*Day + Covid_7AVG * Day + Hour*Borough_Zone + Hour*TMP + Hour*WND + Hour*DEW,data = training_data, family = poisson())
#Mean
sum(training_data$Count) / length(training_data$Count)
# Variance
var(training_data$Count)
#uncomment to get the dispersion paramete
model_P <- glm(Count ~ Date_seq + Day + Borough_Zone + DEW + TMP + WND + holiday + Covid_7AVG + Hour,data = training_data, family = quasipoisson())
dispersion_moded <- summary(model_P)
#uncomment to get the dispersion paramete
model_P <- glm(Count ~ Date_seq + Day + Borough_Zone + DEW + TMP + WND + holiday + Covid_7AVG + Hour,data = training_data, family = quasipoisson())
dispersion_moded <- summary(model_P)
dispersion_moded$dispersion
# Fit the final model
model_P_Final <- glm(Count ~ Date_seq + DEW + TMP + WND + holiday + Covid_7AVG + Hour + Day + Borough_Zone + Day*Borough_Zone + holiday*Borough_Zone + Hour*Day + Covid_7AVG * Day + Hour*Borough_Zone + Hour*TMP + Hour*WND + Hour*DEW,data = training_data, family = quasipoisson())
poisson_final_statistics <- summary(model_P_Final)
poisson_final_statistics
poisson_final_statistics <- summary(model_P_Final)
#poisson_final_statistics
model_NB_I <- glm.nb(Count ~ Date_seq + DEW + TMP + WND + holiday + Covid_7AVG + Hour + Day + Borough_Zone + Day*Borough_Zone + holiday*Borough_Zone + Hour*Day + Covid_7AVG * Day + Hour*Borough_Zone + Hour*TMP + Hour*WND + Hour*DEW,data = training_data)
library(MASS)
model_NB_I <- glm.nb(Count ~ Date_seq + DEW + TMP + WND + holiday + Covid_7AVG + Hour + Day + Borough_Zone + Day*Borough_Zone + holiday*Borough_Zone + Hour*Day + Covid_7AVG * Day + Hour*Borough_Zone + Hour*TMP + Hour*WND + Hour*DEW,data = training_data)
plot(model_NB_I, sub.caption = '')
plot(model_P_Final, sub.caption = '')
# lets take the 1st of march for Brooklyn, the most variate
test_case <- test_data[test_data$Borough_Zone == 'Brooklyn' & test_data$Date == '2022-03-01',]
test_case <- subset(test_case, select = -c(Date))
rownames(test_case) <- test_case$Hour
Pois_predict <- predict(model_P_Final,newdata = test_case, type = 'response')
NegBin_predict <- predict(model_NB_I,newdata = test_case, type = 'response')
# create a dataframe
Type <- c(rep("Poisson Estimate" , 24) , rep("Neg.Bin. Estimate" , 24) , rep("Ground Truth" , 24))
Hour <- rep(test_case$Hour , 3)
Rideshare_Demand <- c(Pois_predict, NegBin_predict, test_case$Count)
datas <- data.frame(Model,Hour,val)
library(ggplot2)
ggplot(datas, aes(fill=Type, y=Rideshare_Demand, x=Hour)) +
geom_bar(width = 0.8, position="dodge", stat="identity") + ggtitle("Comparison of Estimated Rideservice Demand for Brooklyn 1st March 2022") +
xlab("Hour") + ylab("Number of Trips in Brooklyn") + labs(fill = "Estimate Type")
ggsave(
'March_1st_2022_Brooklyn_Prediction.png',
plot = last_plot(),
device = 'png',
path = '../Plots',
scale = 1,
dpi = 300,
)
poisson_final_statistics$coefficients
library(fitzRoy)
fetch_player_stats(season = 2020, source = "fryzigg")
fetch_player_stats(season = 2020, source = "Footywire")
fetch_player_stats(season = 2020, source = "Footy Wire")
fetch_player_stats(season = 2020, source = "footywire")
fetch_player_stats(season = seq(2000, 2022, 1), source = "footywire")
fetch_player_stats(season = seq(2011, 2022, 1), source = "footywire")
fetch_player_stats(season = seq(2012, 2022, 1), source = "footywire")
fetch_player_stats(season = seq(2013, 2022, 1), source = "footywire")
fetch_player_stats(season = seq(2012, 2022, 1), source = "footywire")
fetch_player_stats(season = seq(2011, 2022, 1), source = "footywire")
fetch_player_stats(season = seq(2010, 2022, 1), source = "footywire")
fetch_player_details(team = "Hawthorn", current = FALSE, source = "AFL")
fetch_player_details(team = "Hawthorn", source = "AFL")
fetch_player_details(team = "Hawthorn", current = FALSE, source = "afltables")
fetch_player_details(team = "Hawthorn", current = FALSE, source = "footywire")
fetch_player_details(team = "Hawthorn", source = "Footy Wire")
fetch_player_details(team = "Hawthorn", source = "footywire")
fetch_player_details(team = "Hawthorn", source = "foot ywire")
fetch_player_details(team = "Hawthorn", source = "fryzigg")
fetch_player_details(team = "Hawthorn", source = "afltablesc")
fetch_player_details(team = "Hawthorn", source = "squiggle")
fetch_player_details(team = "Hawthorn", source = "afltables")
setwd("D:/University/AFL Project/AFL Research Repository/notebooks")
player_stats <- fetch_player_stats(season = seq(2010, 2022, 1), source = "footywire")
write.csv(player_stats, file = '../data/raw/player_statistics.csv)
player_stats <- fetch_player_stats(season = seq(2010, 2022, 1), source = "footywire")
write.csv(player_stats, file = '../data/raw/player_statistics.csv')
draftfetch_player_details(team = "Hawthorn",current = FALSE source = "footywire")
draftfetch_player_details(team = "Hawthorn",current = FALSE, source = "footywire")
draftfetch_player_details(team = "Hawthorn", source = "footywire")
fetch_player_details(team = "Hawthorn",current = FALSE, source = "footywire")
fetch_player_details(team = "Hawthorn",current = FALSE, source = "AFL")
fetch_player_details(team = "Hawthorn",current = 'FALSE', source = "AFL")
fetch_player_details(team = "Hawthorn",current = FALSE, source = "AFL")
fetch_player_details_afl(
2010,
team = NULL,
comp = "AFLM",
official_teams = FALSE
)
fetch_player_details_afl(
2010,
team = NULL,
comp = "AFLM"
)
fetch_player_details_afl(
2010,
team = NULL,
)
fetch_player_details_afl(
2011,
team = NULL,
)
fetch_player_details_afl(
2012,
team = NULL,
)
fetch_player_details_afl(
2016,
team = NULL,
)
fetch_player_details_afl(
2015,
team = NULL,
)
fetch_player_details_afl(
2014,
team = NULL,
)
fetch_player_details_afl(
2013,
team = NULL,
)
fetch_player_details_afl(
2012,
team = NULL,
)
fetch_player_details("Hawthorn")
fetch_player_details_footywire()
fetch_player_details_footywire(team = NULL)
fetch_player_details_footywire(team = 'Carlton')
fetch_player_details_footywire(team = 'Carlton', current = FALSE)
fetch_player_details("Adelaide", current = FALSE, comp = "AFLW")
fetch_player_details_afl(
seq(2013,2022,1)
team = NULL,
fetch_player_details_afl(
seq(2013,2022,1),
team = NULL,
comp = "AFLM",
official_teams = FALSE
)
fetch_player_details_afl(
seq(2013,2022,1),
team = NULL,
comp = "AFLM")
fetch_player_details_afl(
seq(2013),
team = NULL,
comp = "AFLM")
fetch_player_details_afl(
c(2013,2014),
team = NULL,
comp = "AFLM")
fetch_player_details_afl(
2013,
team = NULL,
comp = "AFLM")
library(dplyr)
# collect the first year
draft_history <- fetch_player_details_afl(2013,   team = NULL,  comp = "AFLM")
for i in seq(2014, 2022) :
# collect the first year
draft_history <- fetch_player_details_afl(2013,   team = NULL,  comp = "AFLM")
for i in seq(2014, 2022, 1) :
# collect the first year
draft_history <- fetch_player_details_afl(2013,   team = NULL,  comp = "AFLM")
for i in seq(2014, 2022, 1) {
# collect the first year
draft_history <- fetch_player_details_afl(2013,   team = NULL,  comp = "AFLM")
for (i in seq(2014, 2022, 1)) {
temp_history <- fetch_player_details_afl(i,   team = NULL,  comp = "AFLM")
draft_history <- union(draft_history,temp_history)
}
temp_history
draft_history
colnames(temp_history)
colnames(draft_history)
draft_history[1]
draft_history[1,]
draft_history$draftPosition
fetch_player_details_afl(2015,   team = NULL,  comp = "AFLM")
fetch_player_details_afl(2013,   team = NULL,  comp = "AFLM")
fetch_player_details_afl(2016,   team = NULL,  comp = "AFLM")
fetch_player_details_afl(2020,   team = NULL,  comp = "AFLM")
fetch_player_details_afl(2017,   team = NULL,  comp = "AFLM")
fetch_player_details_afl(2018,   team = NULL,  comp = "AFLM")
fetch_player_details_afl(2019,   team = NULL,  comp = "AFLM")
fetch_player_details_afl(2022,   team = NULL,  comp = "AFLM")
fetch_player_details_afltables(team = NULL)
fetch_lineup(season = 2021, round_number = 1, comp = "AFLW")
fetch_lineup(season = 2021, round_number = 1, comp = "AFLW")$position
fetch_lineup(season = 2013, round_number = 1, comp = "AFLM")$position
colnames(draft_history)
# collect the first year
draft_history <- fetch_player_details_afl(2013,   team = NULL,  comp = "AFLM")
for (i in seq(2014, 2022, 1)) {
temp_history <- fetch_player_details_afl(i,   team = NULL,  comp = "AFLM")
if 'position' not in colnames(temp_history) {
# collect the first year
draft_history <- fetch_player_details_afl(2013,   team = NULL,  comp = "AFLM")
for (i in seq(2014, 2022, 1)) {
temp_history <- fetch_player_details_afl(i,   team = NULL,  comp = "AFLM")
if ('position' not in colnames(temp_history)) {
'position' not in c('d', 'dw')
if ('position' not in c('d', 'dw')) {}
if ('position' in c('d', 'dw')) {}
if ('position' %in% c('d', 'dw')) {}
# collect the first year
draft_history <- fetch_player_details_afl(2013,   team = NULL,  comp = "AFLM")
for (i in seq(2014, 2022, 1)) {
temp_history <- fetch_player_details_afl(i,   team = NULL,  comp = "AFLM")
if (!('position' %in% colnames(temp_history))) {
temp_history['position'] <- 'UNKNOWN'
}
draft_history <- union(draft_history,temp_history)
}
draft_history
write.csv(draft_history, file = '../data/raw/draft_history.csv' )
fetch_lineup(season = 2013, round_number = 1, comp = "AFLM")
# collect the first year
game_position <- fetch_lineup(season = 2013, comp = "AFLM")
for (i in seq(2014, 2022, 1)) {
game_position <- fetch_lineup(season = 2013, comp = "AFLM")
if (!('position' %in% colnames(temp_history))) {
game_position['position'] <- 'UNKNOWN'
}
game_position <- union(draft_history,temp_history)
}
# collect the first year
game_position <- fetch_lineup(season = 2013, comp = "AFLM")
for (i in seq(2014, 2022, 1)) {
temp_position <- fetch_lineup(season = i, comp = "AFLM")
game_position <- union(game_position,temp_position)
}
temp_position
colnames(temp_position)
colnames(game_position)
temp_position$lateChanges
temp_position$lateChanges[-50:]
temp_position$lateChanges[-50:,]
temp_position$lateChanges[-50:-1,]
temp_position$lateChanges[-1,]
temp_position$lateChanges[10000,]
temp_position$lateChanges[1000,]
temp_position$lateChanges[100,]
temp_position[100,]
temp_position[100,c(20)]
temp_position[100:1000,c(20)]
temp_position[100:1000temp_position <- subset.data.frame(temp_position, drop = 'lateChanges')
temp_position <- subset.data.frame(temp_position, drop = 'lateChanges')
temp_position <- subset.data.frame(temp_position, subset = c(-20))
temp_position <- subset(temp_position, subset = c(-20))
temp_position <- subset(, subset = c(-20))
temp_position[c(-20)]
# collect the first year
game_position <- fetch_lineup(season = 2013, comp = "AFLM")
for (i in seq(2014, 2022, 1)) {
temp_position <- fetch_lineup(season = i, comp = "AFLM")
if ('lateChanges' %in% colnames(temp_position)) {
myvars <- names(temp_position) %in% c('lateChanges')
temp_position <- temp_position[!myvars]
}
game_position <- union(game_position,temp_position)
}
write.csv(game_position, file = '../data/raw/game_positions.csv')
